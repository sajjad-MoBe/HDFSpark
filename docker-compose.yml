version: '3.8'

services:
  zookeeper:
    image: bitnami/zookeeper:3.8
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - hadoop-network
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zookeeper:2888:3888
      ALLOW_ANONYMOUS_LOGIN: yes
    ports:
      - "2181:2181"

  journalnode1:
    image: bde2020/hadoop-base:2.0.0-hadoop3.2.1-java8
    container_name: journalnode1
    hostname: journalnode1
    command: ["hdfs", "journalnode"]
    networks:
      - hadoop-network
    volumes:
      - journalnode1-data:/hadoop/dfs/journal
    environment:
      - CLUSTER_NAME=test-ha
    ports:
      - "8485:8485"

  journalnode2:
    image: bde2020/hadoop-base:2.0.0-hadoop3.2.1-java8
    container_name: journalnode2
    hostname: journalnode2
    command: ["hdfs", "journalnode"]
    networks:
      - hadoop-network
    volumes:
      - journalnode2-data:/hadoop/dfs/journal
    environment:
      - CLUSTER_NAME=test-ha
    ports:
      - "8486:8485"

  namenode1:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode1
    hostname: namenode1
    networks:
      - hadoop-network
    volumes:
      - ./config/hdfs-site.xml:/etc/hadoop/hdfs-site.xml
      - ./config/core-site.xml:/etc/hadoop/core-site.xml
      - namenode1-data:/hadoop/dfs/name
    ports:
      - "9870:9870"
    environment:
      - CLUSTER_NAME=test-ha
    depends_on:
      - zookeeper
      - journalnode1
      - journalnode2

  namenode2:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode2
    hostname: namenode2
    networks:
      - hadoop-network
    volumes:
      - ./config/hdfs-site.xml:/etc/hadoop/hdfs-site.xml
      - ./config/core-site.xml:/etc/hadoop/core-site.xml
      - namenode2-data:/hadoop/dfs/name
    ports:
      - "9871:9870"
    environment:
      - CLUSTER_NAME=test-ha
    depends_on:
      - zookeeper
      - journalnode1
      - journalnode2

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode1
    hostname: datanode1
    networks:
      - hadoop-network
    volumes:
      - ./config/hdfs-site.xml:/etc/hadoop/hdfs-site.xml
      - ./config/core-site.xml:/etc/hadoop/core-site.xml
      - datanode1-data:/hadoop/dfs/data
    environment:
      - CLUSTER_NAME=test-ha
      
    depends_on:
      - zookeeper
      - journalnode1
      - journalnode2
      - namenode1
      - namenode2

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode2
    hostname: datanode2
    networks:
      - hadoop-network
    volumes:
      - ./config/hdfs-site.xml:/etc/hadoop/hdfs-site.xml
      - ./config/core-site.xml:/etc/hadoop/core-site.xml
      - datanode2-data:/hadoop/dfs/data
    environment:
      - CLUSTER_NAME=test-ha
      
    depends_on:
      - zookeeper
      - journalnode1
      - journalnode2
      - namenode1
      - namenode2

  spark-client:
    image: bitnami/spark:3
    hostname: spark-client
    command: ["tail", "-f", "/dev/null"]
    volumes:
      - ./data:/data
      - ./spark-apps:/apps
      - ./config/core-site.xml:/opt/bitnami/spark/conf/core-site.xml
      - ./config/hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml
    networks:
      - hadoop-network
    depends_on:
      - zookeeper
      - journalnode1
      - journalnode2
      - namenode1
      - namenode2
      - datanode1
      - datanode2

networks:
  hadoop-network:

volumes:
  namenode1-data:
  namenode2-data:
  datanode1-data:
  datanode2-data:
  journalnode1-data:
  journalnode2-data: